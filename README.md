# Planning-Under-Uncertainty-A-Decision-Theoretic-Perspective-
Book Chapter
# 📖 Planning Under Uncertainty  

This repository contains notes and explanations from the book chapter **“Planning Under Uncertainty”**.  
It explores how intelligent agents make decisions when outcomes are unpredictable due to incomplete knowledge, noisy sensors, or stochastic environments.  

---

## 📂 Contents  
- **Introduction** – What is planning under uncertainty & why it matters  
- **Basic Concepts** – Deterministic vs. Non-Deterministic Planning, Sources of Uncertainty  
- **Models**  
  - Markov Decision Processes (MDPs)  
  - Partially Observable MDPs (POMDPs)  
- **Algorithms**  
  - Value Iteration  
  - Policy Iteration  
  - Belief State Space Search  
  - Monte Carlo Methods  
- **Applications** – Robot Navigation, Inventory Management, Autonomous Vehicles  
- **Challenges** – Scalability, Partial Observability, Real-Time Constraints  
- **Recent Advances** – Deep RL, Model-Based RL, Probabilistic Graphical Models, Multi-Agent Planning  

---

## 🚀 Key Takeaways  
- Uncertainty is **inherent in real-world AI & robotics**.  
- **MDPs and POMDPs** provide the mathematical foundation.  
- Algorithms like **Value Iteration & Monte Carlo** help derive optimal policies.  
- Applications span **autonomous systems, logistics, and decision-making AI**.  
- Future research focuses on **scalability, human-AI collaboration, and ethics**.  

---

## 📌 Usage  
This repository serves as a **quick reference** for students and researchers working on:  
- Artificial Intelligence  
- Robotics & Autonomous Systems  
- Reinforcement Learning  
- Operations Research  

---

## 🔗 References  
- *Artificial Intelligence: A Modern Approach* – Russell & Norvig (2009)  
- *Reinforcement Learning: An Introduction* – Sutton & Barto (2018)  
- *Computational Complexity* – Papadimitriou (1994)  

---

